% \red{The content of ``Background'' is in ``{\textbackslash}contents{\textbackslash}background.tex''}

\section{Literature Survey \& Review} 

\subsection{The Diabetes Management Tightrope}

\noindent Managing diabetes often draws parallels with walking a metabolic tightrope. On one side lies the danger of hyperglycaemia and its associated \textit{long-term complications} such as diabetic retinopathy(damage to blood vessels in the eye leading to blindness) or renal function impairment (diabetic nephropathy), while on the other lies the \textit{immediate peril of hypoglycaemia}. For the longest time, clinicians have helped patients navigate this delicate balance, by utilising methods or practises that show where they are, but not necessarily where they are going, in terms of blood glucose measurements. Such a reactive approach with little account for anticipative elements has made hypoglycaemic episodes an unavoidable consequence of striving for tight glycaemic control. 

\vspace{5pt}
\noindent This "tightrope" extends beyond just taking efforts to stay safe, requiring diabetics and patients to perform constant risk assessments in everyday life. UK driving law from the DVLA mandates a blood glucose reading of above 5.0mmol/L with a repeat test every two hours for longer journeys in order to be considered safe to drive. Patients are required to carry a "hypo kit" with fast-acting glucose at all times. The worry about having episodes in public and having to rely on the awareness of strangers or being a hindrance to social situations is a constant concern. As discussed \hyperref[sec:clinicalOverview]{here previously} this also places notable financial strain on NHS resources through emergency or ambulance costs.

\vspace{5pt}
\noindent With scientific and technological progress that inevitably comes with time, comes the promise of a potential safety net: the ability to anticipate or foresee signs of an episode before they present. The dangerous tightrope walk can then be transformed into a manageable path, with the help of predictive systems built with advanced sensing technologies and computational power, that can assist patients to take pre-emptive action. This review will chart the progress in this field, understanding the methodologies and ideas that have been applied to forecast hypoglycaemic events, from early tracking methods to highly optimized modern algorithms.


\subsection{Methods Of Monitoring Blood Glucose Over Time}

\noindent The success rate of recognising patterns in blood glucose has been vastly upgraded through the years, spurred by both technological and procedural refinements in the monitoring of blood glucose, but it has been an arduous journey to get here. The earliest methods of testing blood glucose involved urine tests, where chemical reagents like Benedict's solution were used which changed colour in the presence of sugar. Such methods were only qualitative and retroactive - they offered no actionable information as they confirmed that blood glucose had been elevated at the time of the test or in the recent past. The first blood glucose meters did not appear until the 1960s, were large and cumbersome to work with, and were mainly found in clinics. Smaller, portable meters became available around the 1970s - 1980s yet still all such meters had to be used repetitvely throughout the day, offering only a snapshot of blood glucose level in time without any means of showing a trend, stability or lack thereof. 

\vspace{5pt}
\noindent The introduction of Continuous Glucose Monitoring (CGM) solutions from 2005 onwards completely revolutionized diabetic healthcare, allowing measurements to be taken effortlessly through sensors attached to the body. Medtronic and Dexcom's devices released after 2015 with highly improved sensor accuracy and user-friendliness even allowed connecting to smartphones and automatic insulin pumps, which could automatically stop insulin delivery if the patient did not respond to an alarm. Today's CGM's are even more cutting-edge, in that they continuously transmit data to a receiver. They are smartphone-app based for ease of use, offering enhanced features to show the trend and speed of glucose changes, alarms and alerts to proactively warn users, as well as sharing data with family members or doctors for remote monitoring and emergency handling \cite{evolutionOfCGM}. 

\vspace{5pt}
\noindent In modern times, there is huge amounts of data available to probe into, but the challenge lies in finding the correct relevant features, at the correct level of granularity as well as the right distribution, as medical data is exceptionally rarely obtained in balanced form. The availability of rich continuous streams of data from CGMs has stimulated additional research dedicated to developing and applying algorithms to both forecast hypoglycaemic events as well as identify outliers or patterns within the data, and I delve into this next.

\subsection{Review Of Relevant Literature and Similar Research}

\noindent A substantial body of literature now exists on the development of models for predicting hypoglycaemia in various settings. In many scenarios, a significant proportion of the research focuses on optimizing predictive accuracy of models. For instance H. Yang et al. in 2022 \cite{yangHaoJMIRMedicalInformatics} have used electronic health records(EHR) of patients admitted to West China Hospitals to develop a predictive model based on laboratory derived biomarkers (like lipoproteins, creatinine, globulin etc.).  A similar research to this was undertaken by S. Mantena et al. \cite{sMantenaCriticallyIll}  but on the publicly-available eICU Collaborative Research v2.0 database (eICU-CRD) that holds de-identified data for 200,000+ admissions in 553 ICUs across the USA. In reinforcement to this, UK-based studies have also been executed by Y. Ruan et al. \cite{yRuanOxfordHypoRiskPred} on four years worth of EHRs provided by Oxford University Hospitals NHS Foundation Trust in which they compared the performance of eighteen different predictive models based on demographic, laboratory, vital signs and previous medication predictors.  

\vspace{5pt}
\noindent A significant commonality was observed in all the three research works, which I have incorporated into my approach as well - the emergence of XGBoost as the best predictive model with highest Area Under Receiver Operating Characteristic Curve(AUROC). Even though all studies produce excellent results in terms of predictive performance, they are not primarily aimed at finding the critical values or "turning points" of the predictors at which predictions / classifications change, which is my objective for this project that also lines up with GSTT priorities.

\vspace{5pt}
\noindent It needs to be stressed that achieving high accuracy on a regulated dataset in controlled circumstances is different to creating a mechanism or system that is successful, effective and dependable in a real-world clinical setting. While also comparing the performance of ML models on a new dataset, I am exploring a completely new and unique patient population, which requires a holistic approach towards the data. There is scarce research that scouts the dataset to create insights about patient population, such as the spread or extent of hypoglycaemia across wards, as the major focus is primarily predictive or comparative modelling. 

% \vspace{5pt}
% \noindent A holistic approach that aligns with my own project objectives was discovered in A. Zale's and N. Mathioudakis' research \cite{aZaleInpatientGlucosePred} to design ML models for inpatient glucose prediction.

\subsection{A Novel Contribution to ML-based Glycaemia management in the NHS}

\vspace{5pt}
\noindent To my knowledge, the majority of published studies or models are developed using well maintained and curated datasets. Additionally, most analyses seen prior are based on a relatively homogeneous patient population, from a major location in countries like USA or China. These may not be generalisable across different geographies or demographics. This project uses an ethnically and socioeconomically diverse patient cohort from a leading NHS Trust in London, which has produced an analysis that is robust across various age and demographic groups. It also demonstrates that disparate data streams from different verticals of the NHS Epic EHR system can be integrated and harmonised to produce real world benefits after research, to create a working model specific to the NHS that other Trusts can follow. It emphasises on the "human insights" aspect of analysis more by having greater emphasis on patient features as opposed to laboratory measurements. Most analyses have a strictly methodical and statistical approach with little insights being generated around the actual groups of patients within the data. 
 